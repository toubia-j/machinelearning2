{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Importation des bibliothèques**\n"
      ],
      "metadata": {
        "id": "JI3WrRWiMPjt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBuVkvaoFZ8C"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import joblib\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, hamming_loss\n",
        ")\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classe pour charger les données**"
      ],
      "metadata": {
        "id": "FFiAbe2nMYZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoader:\n",
        "    def load_data(file_path: str):\n",
        "        \"\"\"Charge et prépare les données pour la classification multi-label\"\"\"\n",
        "        file_path = \"books_dataset.xls\"\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        # Nettoyage des colonnes\n",
        "        df = df.dropna(subset=['description', 'categories'])\n",
        "        df['description'] = df['description'].fillna('').str.strip()\n",
        "        df['categories'] = df['categories'].astype(str).str.split(', ')\n",
        "\n",
        "        # Conversion des catégories en matrice binaire\n",
        "        mlb = MultiLabelBinarizer()\n",
        "        y = mlb.fit_transform(df['categories'])\n",
        "\n",
        "        return df['description'], y, mlb"
      ],
      "metadata": {
        "id": "RAb1lOAjMUmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classe pour prétraiter les donnée**\n"
      ],
      "metadata": {
        "id": "T2mKjl3rMe0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Preprocessor(TransformerMixin, BaseEstimator):\n",
        "    \"\"\"Préprocesseur pour nettoyer les descriptions et appliquer TF-IDF\"\"\"\n",
        "    def __init__(self):\n",
        "        self.vectorizer = TfidfVectorizer(\n",
        "            stop_words='english', max_features=5000, min_df=2, max_df=0.95\n",
        "        )\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        X = pd.Series(X).astype(str)\n",
        "        self.vectorizer.fit(X)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = pd.Series(X).astype(str)\n",
        "        return self.vectorizer.transform(X)\n"
      ],
      "metadata": {
        "id": "dwPtt7x1MdU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classe pour entraîner et évaluer les modèles**\n"
      ],
      "metadata": {
        "id": "WJtzzVfaMm7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelTrainer:\n",
        "    def __init__(self, models, metrics):\n",
        "        self.models = models\n",
        "        self.metrics = metrics\n",
        "        self.results = []\n",
        "\n",
        "    def train_and_evaluate(self, X_train, X_test, y_train, y_test):\n",
        "        \"\"\"Entraîne et évalue tous les modèles\"\"\"\n",
        "        for model_name, model in tqdm(self.models.items(), desc=\"Training models\"):\n",
        "            model.fit(X_train, y_train)  # Entraîner le modèle\n",
        "            predictions = model.predict(X_test)  # Prédire sur les données de test\n",
        "\n",
        "            # Calculer toutes les métriques\n",
        "            metrics_results = {\n",
        "                metric_name: metric_func(y_test, predictions)\n",
        "                for metric_name, metric_func in self.metrics.items()\n",
        "            }\n",
        "\n",
        "            # Sauvegarder les résultats\n",
        "            self.results.append({'model': model, 'name': model_name, **metrics_results})\n",
        "\n"
      ],
      "metadata": {
        "id": "Z-DFLT4yMld5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classe pour exécuter l'entraînement**\n"
      ],
      "metadata": {
        "id": "1QuS5c-jMzwA"
      }
    },
    {
      "source": [
        "import os\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class ExperimentRunner:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "\n",
        "    def run(self, X, y):\n",
        "        \"\"\"Exécute l'expérience complète.\"\"\"\n",
        "        # Diviser les données en entraînement et test\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=self.config['test_size'], random_state=42\n",
        "        )\n",
        "\n",
        "        # Filtrer les colonnes avec des classes vides dans l'ensemble d'entraînement\n",
        "        valid_columns = y_train.sum(axis=0) > 0\n",
        "        y_train = y_train[:, valid_columns]\n",
        "        y_test = y_test[:, valid_columns]\n",
        "\n",
        "        # Prétraiter les données\n",
        "        preprocessor = self.config['preprocessor']()\n",
        "        X_train_transformed = preprocessor.fit_transform(X_train)\n",
        "        X_test_transformed = preprocessor.transform(X_test)\n",
        "\n",
        "        # Entraîner et évaluer les modèles\n",
        "        trainer = ModelTrainer(self.config['models'], self.config['metrics'])\n",
        "        trainer.train_and_evaluate(X_train_transformed, X_test_transformed, y_train, y_test)\n",
        "\n",
        "        # Sauvegarder les modèles avec pickle\n",
        "        self.save_models(trainer.results, \"saved_models\")\n",
        "\n",
        "        return trainer.results\n",
        "\n",
        "    def save_models(self, results, save_dir):\n",
        "        \"\"\"Sauvegarde les modèles entraînés avec pickle.\"\"\"\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "        for result in results:\n",
        "            model_obj = result['model']  # Objet du modèle entraîné\n",
        "            model_name = result['name'].replace(' ', '_').lower()  # Nom du modèle\n",
        "\n",
        "            # Vérification avant sauvegarde\n",
        "            if not hasattr(model_obj, \"fit\") or not hasattr(model_obj, \"predict\"):\n",
        "                print(f\"Le modèle {model_name} n'est pas valide. Ignoré.\")\n",
        "                continue\n",
        "\n",
        "            # Sauvegarde du modèle\n",
        "            file_path = os.path.join(save_dir, f\"{model_name}.pkl\")\n",
        "            with open(file_path, \"wb\") as file:\n",
        "                pickle.dump(model_obj, file)\n",
        "                print(f\"Modèle sauvegardé dans {file_path}\")\n",
        "\n",
        "    def load_model(self, filepath):\n",
        "        \"\"\"Charge un modèle entraîné depuis un fichier pickle.\"\"\"\n",
        "        with open(filepath, \"rb\") as file:\n",
        "            model = pickle.load(file)\n",
        "            print(f\"Modèle chargé depuis {filepath}\")\n",
        "            return model\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "oD8Pq2VLX6Zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Configuration de l'expérience**\n"
      ],
      "metadata": {
        "id": "x256ZCbKNBVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG = {\n",
        "    'test_size': 0.2,  # Pourcentage des données pour le test\n",
        "    'preprocessor': Preprocessor,  # Classe de prétraitement\n",
        "    'models': {  # Modèles à entraîner\n",
        "        'Random Forest': OneVsRestClassifier(RandomForestClassifier(n_estimators=10, random_state=42)),\n",
        "        'k-Nearest Neighbors': OneVsRestClassifier(KNeighborsClassifier(n_neighbors=3)),\n",
        "        'Gradient Boosting': OneVsRestClassifier(GradientBoostingClassifier(n_estimators=10, random_state=42))\n",
        "    },\n",
        "    'metrics': {  # Métriques pour l'évaluation\n",
        "        'hamming_loss': hamming_loss,\n",
        "        'subset_accuracy': accuracy_score,\n",
        "        'micro_f1': lambda y_true, y_pred: f1_score(y_true, y_pred, average='micro', zero_division=1),\n",
        "        'macro_f1': lambda y_true, y_pred: f1_score(y_true, y_pred, average='macro', zero_division=1)\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "_y1kbNubM_Ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exécution principal**"
      ],
      "metadata": {
        "id": "ZG3z6COKNIjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Charger les données\n",
        "    file_path = \"books_dataset.xls\"\n",
        "\n",
        "    # Charger et préparer les données\n",
        "    X, y, mlb = DataLoader.load_data(file_path)\n",
        "    CONFIG['mlb'] = mlb\n",
        "\n",
        "    # Lancer l'expérience\n",
        "    runner = ExperimentRunner(CONFIG)\n",
        "    results = runner.run(X, y)\n",
        "\n",
        "    # Afficher les résultats\n",
        "    results_df = pd.DataFrame(results)\n",
        "    print(\"Résultats de l'entraînement :\")\n",
        "    print(results_df)\n",
        "\n",
        "    # Vérification de la sauvegarde\n",
        "    print(\"Les modèles ont été sauvegardés dans le répertoire 'saved_models'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgYWgDU8NF2J",
        "outputId": "dac03768-af0f-4d9d-89b2-9554901a3ef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training models: 100%|██████████| 3/3 [02:22<00:00, 47.62s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modèle sauvegardé dans saved_models/random_forest.pkl\n",
            "Modèle sauvegardé dans saved_models/k-nearest_neighbors.pkl\n",
            "Modèle sauvegardé dans saved_models/gradient_boosting.pkl\n",
            "Résultats de l'entraînement :\n",
            "                                               model                 name  \\\n",
            "0  OneVsRestClassifier(estimator=RandomForestClas...        Random Forest   \n",
            "1  OneVsRestClassifier(estimator=KNeighborsClassi...  k-Nearest Neighbors   \n",
            "2  OneVsRestClassifier(estimator=GradientBoosting...    Gradient Boosting   \n",
            "\n",
            "   hamming_loss  subset_accuracy  micro_f1  macro_f1  \n",
            "0      0.000570         0.865522  0.911776  0.901344  \n",
            "1      0.001285         0.623748  0.767773  0.801033  \n",
            "2      0.002046         0.574392  0.736000  0.870639  \n",
            "Les modèles ont été sauvegardés dans le répertoire 'saved_models'.\n"
          ]
        }
      ]
    }
  ]
}